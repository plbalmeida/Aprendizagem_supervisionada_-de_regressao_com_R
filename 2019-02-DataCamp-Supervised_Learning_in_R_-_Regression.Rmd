---
title: "Aprendizagem supervisioanda com R"
author: "Pedro Almeida"
date: "17 de fevereiro de 2019"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## 1) O que é uma regressão?

Na primeira parte desse código, será apresentdo o conceito de regressão do ponto de vista da aprendizagem de máquina. Será apresentado o método de regressão fundamental: a regressão linear. Mostrarei como ajustar um modelo de regressão linear e fazer previsões a partir do modelo.

### Codando uma regressão com uma variável independente

Nessa primeira parte utilizaremos os dados de desemprego de homens e mulheres dos Estados Unidos ao logo de vários anos, fonte dos dados: <http://college.cengage.com/mathematics/brase/understandable_statistics/7e/students/datasets/slr/frames/slr02.html>.

A tarefa aqui é prever a taxa de desemprego feminino a partir da taxa observada de desemprego masculino, respectivamente as variáveis no dataset são female_unemployment e male_unemployment.

```{r, message=FALSE, warning=FALSE}

# importando os dados
unemployment <- read.delim(file = "unemployment.txt", sep = "")

# verificando os quantis dos dados
summary(unemployment[,2:3])

# definindo a fórmula que expressa female_unemployment em função de male_unemployment
fmla <- female_unemployment ~ male_unemployment

# fitando o modelo em unemployment_model
unemployment_model <-  lm(fmla, data = unemployment)

# visualizando o modelo 
unemployment_model

```

O coeficiente do desemprego masculino é positivo, de modo que o desemprego feminino aumenta à medida que o desemprego masculino aumenta, lembrando que a regressão linear é a mais básica das abordagens de regressão.

### Examinando o modelo de regressão linear

Utilizando a função summary() é possível verificar os residuais do modelo, o coeficiente beta, o erro padrão, o valor t e a significancia estatística da variável independente no modelo. Assim como outras métricas de acurácia do modelo que abordarei mais a frente.

```{r, message=FALSE, warning=FALSE}

summary(unemployment_model)

```

### Fazendo predições a partir do modelo

```{r, message=FALSE, warning=FALSE}

# predizendo o desemprego entre mulheres a partir da taxa de desemprego entre homens
newrates <- data.frame(male_unemployment = 5) # taxa de desemprego entre homens igual a 5%
pred <- predict(unemployment_model, newdata = newrates)
pred

```

### Visualizando o modelo de regressão linear

```{r, message=FALSE, warning=FALSE}

library(ggplot2)

ggplot(unemployment, aes(x = male_unemployment, y = female_unemployment)) + 
  geom_point() +
  geom_abline(color = "darkblue")

```

### Regressão multivariada

Nos exemplos de regressão multivariada será utilizado o dataset bloodpressure, no qual irei modelar a pressão em função o peso e idade, fonte dos dados <http://college.cengage.com/mathematics/brase/understandable_statistics/7e/students/datasets/mlr/frames/frame.html>.

```{r, message=FALSE, warning=FALSE}

# importando os dados
bloodpressure <- read.delim(file = "bloodpressure.txt", sep = "")

# verificando os quantis dos dados
summary(bloodpressure[,2:4])

# criando a fórmula
fmla <- blood_pressure ~ age + weight

# fitando o modelo: bloodpressure_model
bloodpressure_model <- lm(fmla, data = bloodpressure)

# examinando o modelo
summary(bloodpressure_model)

```

Uma das vantagens da regressão linear é que você pode interpretar os efeitos de cada variável independente. Nesse caso, os coeficientes para idade e peso são positivos, o que indica que a pressão sanguínea tende a aumentar à medida que a idade e o peso aumentam.

### Fazendo predições do modelo de regressão multivariada e visualizando

```{r, message=FALSE, warning=FALSE}

# predizendo pressão usando o modelo bloodpressure_model
bloodpressure$prediction <- predict(bloodpressure_model)

# visualizando os resultados
ggplot(bloodpressure, aes(x = prediction, y = blood_pressure)) + 
    geom_point() +
  geom_abline(color = "darkblue")

```

Os resultados do modelo ficaram bem ajustados aos dados observados da variável dependente, indicando que o modelo se ajusta bem aos dados de treinamento. A partir de uma perspectiva de predição, a regressão linear multivariada se comporta da mesma forma que a simples (de uma variável).

## 2) Treinando e avaliando modelos de regressão

Agora que tivemos uma intuição sobre modelos mais básicos de regressão linear, aprenderemos a avaliar o desempenho de nossos modelos. Analisaremos a avaliação de um modelo graficamente e analisaremos duas métricas básicas para modelos de regressão. Também aprenderemos como treinar um modelo de modo  que ele funcione bem para dados não vistos no dataset, e não apenas em dados de treinamento.

### Avaliando o modelo unemployment_model graficamente

Aqui visualizaremos o quanto o modelo e suas predições podem errar. Na sequência faremos o cálculo do quanto um modelo pode errar em média.

```{r, message=FALSE, warning=FALSE}

# predição do modelo
unemployment$predictions <- predict(unemployment_model)

# predição X variável dependente
ggplot(unemployment, aes(x = predictions, y = female_unemployment)) + 
  geom_point() +
  geom_abline(color = "darkblue")

# calculando o residual
unemployment$residuals <- unemployment$female_unemployment - unemployment$predictions

# visualizando os residuais do modelo
ggplot(unemployment, aes(x = predictions, y = residuals)) + 
  geom_pointrange(aes(ymin = 0, ymax = residuals)) + 
  geom_hline(yintercept = 0, linetype = 3) + 
  ggtitle("residuals vs. linear model prediction")

```

### Raíz da média dos residuais ao quadrado

Em inglês é root-mean-square error (RMSE), que mostra o quanto a predição do modelo está errando, essa é uma das métricas de acurácia de um modelo de regressão linear.

```{r, message=FALSE, warning=FALSE}

# criando um objeto para os residuais do modelo
res <- unemployment$residuals

# calculando a RMSE
rmse <- sqrt(mean(res^2))
rmse

# calculando o desvio padrão da variável dependente
sd_unemployment <- sd(unemployment$female_unemployment)
sd_unemployment

```

Um RMSE menor que o desvio padrão da variável dependente, sugere um modelo que prevê bem.

### Cálculo do R²

Agora que vimos o RMSE das previsões do modelo, você examinará como o modelo se ajusta aos dados: ou seja, quanto de variação ele explica, e isso é feito usando R².

o R² é dado por:

$$R² = 1- \frac{\sum_{i=1}^n (y_i-\hat{y}_i)^2}{\sum_{i=1}^n (y_i-\overline{y})^2} $$

O R² sempre vai de 0 até 1, indicando em percentagem o quanto o modelo consegue explicar os valores observados da variável dependente.

Uma maneira que gosto de pensar o R² é da seguinte maneira:

1) Olhando a divisão sem o 1 subtraindo fica mais intuitivo entender o R²; 

2) O numerador é a **soma dos quadrados dos residuais** do modelo, lembra que vimos os residuais do modelo um pouco mais acima no código? Então, aqui somamos todas as diferenças entre os valores observados da variável dependente e as predições do modelo (que são os y com chapéu) e elevamos ao quadrado para eliminar os possíveis sinais negativos dessas subtrações;

3) O denominador é a **soma dos quadrados dos erros** dos valores observados da variável dependente. Essse "erro" é a diferença entre os valores observados da variável dependente e a média da variável dependente (o y com traço em cima), elevamos ao quadrado para evitar diferenças com sinal negativo e somamos todos os quadrados dos erros;

4) Legal, a divisão entre a **soma dos quadrados dos residuais** do modelo e a **soma dos quadrados dos erros** da variável dependente, nos mostra o quanto da variável dependente é explicada pelo modelo como se fosse explicada pela média da variável dependente (e claro, nós queremos que nosso modelo explique melhor do que a média da variável dependente ok?). Exemplo: se essa divisão for igual a 0,2 quer dizer que 20% da variável dependente é explicada pelo modelo assim como é explicada pela média da variável dependente, ou seja, 20% das vezes não há diferença entre os residuais do modelo (que é o quanto o modelo erra) e o erro da variável dependente;

5) Logo, a soma dos residuais do modelo é bem menor que a soma dos erros da variável dependente, isso quer dizer que 80% das vezes o modelo está mais ajustado a distribuição dos dados da variável dependente e explica a variável dependente melhor que a média, ou seja 80% da variável dependente é explicada pelo modelo!

Agora vamos ver na prática:

```{r, message=FALSE, warning=FALSE}

# cálculo do da soma dos residuais ao quadrado (numerador)
rss <- sum(unemployment$residuals^2)
rss

# cálculo da soma dos erros ao quadrado (denominador)
fe_mean <- mean(unemployment$female_unemployment) # média da variável dependente
tss <- sum((unemployment$female_unemployment - fe_mean)^2)
tss

# cálculo do R²
rsq <- 1 - (rss/tss)
rsq

```

Legal! o R² é de 0,8213157, isto significa que 82,13% da variável dependente consegue ser explicada pelo modelo!

### Gerando datasets de treino e teste

Para os seguintes exemplos usarei o dataset mpg do pacote ggplot2, esse dataset contém características de vários modelos de carros com diferentes anos de fabricação. O objetivo aqui será predizer o consumo de combustível na cidade e na estrada pelos carros.

Nós iremos explodir o dataset mpg em um dataset de treino contendo 75% das observações do dataset, e um de treino contendo 25% das observações. 

```{r, message=FALSE, warning=FALSE}

# explorando o dataset
summary(mpg)
dim(mpg)

# criando a amostra aleatória do data set
set.seed(1)
sample_rows <- sample(nrow(mpg), nrow(mpg) * 0.75)

# criando o data set de treino
mpg_train <- mpg[sample_rows, ]

# criando o data set de teste
mpg_test <- mpg[-sample_rows, ]

# Use nrow() to examine mpg_train and mpg_test
nrow(mpg_train)
nrow(mpg_test)

```

### Treinando o modelo usando os datasets de treino e de teste

```{r, message=FALSE, warning=FALSE}

# criando a fórmula expressando o consumo de combustível urbano (feature cty) em função do consumo na estrada (feature hwy)
(fmla <- cty ~ hwy)

# modelo utilizando o dataset de treino 
mpg_model <- lm(fmla, data = mpg_train)

# verificando o modelo
summary(mpg_model)

```

A seguir utilizaremos o modelo mpg_model para predições sobre o dataset de treino 

```{r, message=FALSE, warning=FALSE}

library(Metrics) # para função rmse
library(tsensembler) # para função r_squared

# predizendo o consumo urbano de combustível pelo consumo na estrada usando o dataset de treino
mpg_train$pred <- predict(mpg_model)

# predizendo o consumo urbano de combustível pelo consumo na estrada usando o dataset de teste
mpg_test$pred <- predict(mpg_model, newdata = mpg_test)

# verificando o erro (RMSE) dos datasets de treino e de teste
rmse_train <- rmse(mpg_train$pred, mpg_train$cty)
rmse_train

rmse_test <- rmse(mpg_test$pred, mpg_test$cty)
rmse_test

# verificando o R² dos datasets de treino e de teste
rsq_train <- r_squared(mpg_train$pred, mpg_train$cty)
rsq_train

rsq_test <- r_squared(mpg_test$pred, mpg_test$cty)
rsq_test

# visualizando as predições (no eixo x) pela variável dependente cty (no eixo y) do dataset de teste
ggplot(mpg_test, aes(x = pred, y = cty)) + 
  geom_point() + 
  geom_abline(color = "darkblue")

```

Impressionante! O R² do dataset de teste está melhor que o dataset de treino.

### Validação cruzada

A validação cruzada é uma técnica para avaliar a capacidade de generalização de um modelo, a partir de um conjunto de dados. Esta técnica é amplamente empregada em problemas onde o objetivo da modelagem é a predição. Busca-se então estimar o quão preciso é este modelo na prática, ou seja, o seu desempenho para um novo conjunto de dados. Fonte: <https://pt.wikipedia.org/wiki/Validação_cruzada>

```{r, message=FALSE, warning=FALSE}

library(vtreat) # para a função kWayCrossValidation

# número de linhas do dataset
nRows <- nrow(mpg)

# criando uma lista com três reamostragens dos datasets de treino e de teste
splitPlan <- kWayCrossValidation(nRows, 3, NULL, NULL)

# verificando as reamostragens
str(splitPlan)

```

Agora vamos usar a lista de reamostragens criadas.

```{r, message=FALSE, warning=FALSE}

# rodando o 3-fold cross validation do slitPlan

k <- 3 # número de reamostragens

mpg$pred.cv <- 0 

for(i in 1:k) {
  split <- splitPlan[[i]]
  model <- lm(cty ~ hwy, data = mpg[split$train, ])
  mpg$pred.cv[split$app] <- predict(model, newdata = mpg[split$app, ])
}

```

Vamos comparar a acurácia do modelo para todos os dados e acurácia para os dados reamostrados pela validação cruzada.

```{r, message=FALSE, warning=FALSE}

# modelo de todos os dados do dataset eo RMSE
mpg$pred <- predict(lm(cty ~ hwy, data = mpg))
rmse(mpg$pred, mpg$cty)

# RMSE das predições da validação cruzada
rmse(mpg$pred.cv, mpg$cty)

```

Legal! Calculamos o erro para dados não vistos através da validação cruzada!

**Outras considerações:** Antes de seguir com técnicas de regressão mais avançadas, examinaremos outros problemas de modelagem: modelagem com variáveis categóricas, interações entre variáveis e quando você pode considerar a transformação de variáveis independentes (de entrada) e dependentes (de saída) antes da modelagem. Embora as técnicas de regressão mais sofisticadas gerenciem alguns desses problemas automaticamente, é importante estar ciente deles, a fim de entender quais métodos lidam melhor com esses problemas.

## 3) Variáveis categóricas no modelo

Nessa parte, chamaremos a função model.matrix() para examinar como o R representa dados com entradas categóricas e numéricas para modelagem. Usaremos o dataset flowers do pacote Sleuth3 que possue as seguintes variáveis:

* Flowers: média de flores da planta limnanthes floccosa;

* Intensity: a intensidade de de luz que a planta recebeu;

* Time: com as classes Late e Early, que mostra quando que no ciclo de vida da planta ela recebeu mais luz com intensidade;

O objetivo aqui é prever a florada (Flowers) da planta em função do tempo (Time) e da intensidade de luz (Intensity).

```{r, message=FALSE, warning=FALSE}

library(Sleuth3)

# explorando o dataset
flowers <- case0901
flowers$Time <- ifelse(flowers$Time == 1, "Late", "Early")
str(flowers)

# usando a função unique() é possível ver quais são os valores possíveis da variável Time
unique(flowers$Time)

# fórmula que expressa Flowers em função de Intensity e Time
fmla <- as.formula("Flowers ~ Intensity + Time")

# use o fmla e a função model.matrix para ver como os dados são representados para modelagem
mmat <- model.matrix(fmla, flowers)

# verificando as primeiras 20 linhas do dataset flowers
head(flowers, n = 20)

# verificando as primeiras 20 linhas do dataset mmat
head(mmat, n = 20)

```

Agora você pode ver como a maioria das funções de modelagem no R representam variáveis categóricas internamente.

```{r, message=FALSE, warning=FALSE}

# modelo
flower_model <-  lm(fmla, data = flowers)

# usando a função summary no mmat para lembrar como fica a estruta dos dados 
summary(mmat)

# examinando o modelo
summary(flower_model)

# predizendo o número de flores
flowers$predictions <- predict(flower_model)

# visualizando as predições
ggplot(flowers, aes(x = predictions, y = Flowers)) + 
  geom_point() +
  geom_abline(color = "darkblue")

```

Legal! Fizemos um modelo com variável categórica!

## 4) Modelando interações

Nessa parte, usaremos interações entre as variáveis para modelar o efeito do gênero e da atividade gástrica no metabolismo do álcool.

O dataset alcohol possui as seguintes variáveis:

* Metabol: taxa de matabolismo de álcool;

* Gastric: a taxa de atividade desidrogenase gástrica do álcool;

* Sex: sexo masculino ou feminino;

```{r, message=FALSE, warning=FALSE}

library(robustbase) # para importar o dataset alcohol

alcohol <- read.csv("alcohol.csv", sep = ";")

# alcohol is in the workspace
summary(alcohol)

# fórmula do modelo sem interação
fmla_add <- Metabol ~ Gastric + Sex

# fórmula com interação entre variáveis
fmla_interaction <- Metabol ~  Gastric + Gastric:Sex

# fitando o modelo sem interação
model_add <- lm(fmla_add, data = alcohol)

# fitando o modelo com interação
model_interaction <- lm(fmla_interaction, data = alcohol)

# verificando os dois modelos
summary(model_add)
summary(model_interaction)

```

A interação entre as variáveis parece dar um melhor ajuste aos dados.

Como esse dataset é pequeno, usaremos a validação cruzada para simular predições com dados não vistos.

```{r, message=FALSE, warning=FALSE}

library(tidyverse) # para as funções gather, mutate etc

# criando o arquivo com 3 reamostragens
set.seed(34245)  # set the seed for reproducibility
splitPlan <- kWayCrossValidation(nrow(alcohol), 3, NULL, NULL)

# modelo das reamostragens sem interação
alcohol$pred_add <- 0  # vetor de predição

for(i in 1:3) {
  split <- splitPlan[[i]]
  model_add <- lm(fmla_add, data = alcohol[split$train, ])
  alcohol$pred_add[split$app] <- predict(model_add, newdata = alcohol[split$app, ])
}

# modelo das reamostragens com interação
alcohol$pred_interaction <- 0 # vetor de predição

for(i in 1:3) {
  split <- splitPlan[[i]]
  model_interaction <- lm(fmla_interaction, data = alcohol[split$train, ])
  alcohol$pred_interaction[split$app] <- predict(model_interaction, newdata = alcohol[split$app, ])
}

# RMSE
alcohol %>% 
  gather(key = modeltype, value = pred, pred_add, pred_interaction) %>%
  mutate(residuals = Metabol - pred) %>%
  group_by(modeltype) %>%
  summarize(rmse = sqrt(mean(residuals^2)))

```

A validação cruzada mostrou aqui que um modelo com interação dá  melhores predições.

## 5) Transformação da variável resposta

```{r, message=FALSE, warning=FALSE}

# carregando o arquivo
library(readxl)
fdata <- read_excel(path = "fdata.xlsx", sheet = 1)

# verificando os quantis
summary(fdata)

# examinando os dados: gerando resumos para as classes de compras grandes e pequenas
fdata %>% 
  group_by(label) %>% # agrupando por compras pequenas e grandes
  summarize(min  = min(y), # valor mínimo do y
            mean = mean(y), # média do y
            max  = max(y)) # valor máximo do y

# adicionando as colunas de residuais e de erro relativo
fdata2 <- fdata %>% 
  group_by(label) %>% # agrupando pela variável "label"
  mutate(residual = pred - y, # residual
         relerr   = residual/y) # erro relativo

# comparando o RMSE e o RMSE relativo dos grupos de compras grandes e pequenas:
fdata2 %>% 
  group_by(label) %>% 
  summarize(rmse = sqrt(mean(residual^2)), # RMSE
            rmse.rel = sqrt(mean(relerr^2))) # Raíz da média dos erros relativos ao quadrado
            
# visualizando a predição de ambos grupos de compra
ggplot(fdata2, aes(x = pred, y = y)) + 
  geom_point() + 
  geom_abline(color = "darkblue") + 
  facet_wrap(~ label, ncol = 1, scales = "free") + 
  ggtitle("variável dependente X predição")

```

Observe a partir deste exemplo como um modelo com RMSE maior ainda pode ser melhor, se os erros relativos forem mais importantes que os erros absolutos.

Agora  veremos como modelar uma variável dependente log-transformada, usaremos o dataset income_train e income_test. 

```{r, message=FALSE, warning=FALSE}

# carregando os datasets de treino e de teste
income_train <- read_excel(path = "income_train.xlsx" , sheet = 1)
income_test <- read_excel(path = "income_test.xlsx" ,sheet = 1)

# examinando a variável Income2005 na dataset de treino
summary(income_train$Income2005)

# fórmula para o log da variável Income2005
fmla.log <- log(Income2005) ~ Arith + Word + Parag + Math + AFQT

# modelo
model.log <- lm(fmla.log, data = income_train)

# fazendo predições com o dataset de teste
income_test$logpred <- predict(model.log, newdata = income_test)
summary(income_test$logpred)

# convertendo as predições para unidades monetárias
income_test$pred.income <- exp(income_test$logpred)
summary(income_test$pred.income)

# visualizando as predições X variável dependente
ggplot(income_test, aes(x = pred.income, y = Income2005)) + 
  geom_point() + 
  geom_abline(color = "darkblue")

```

Lembrando que quando transformarmos a variável dependente antes da modelagem, é necessário inverter a transformação das predições resultantes após a aplicação do modelo.

Agora vamos comparar o RMSE e a raíz da média dos erros relativos ao quadrado. Vamos verificar como a transformação de log da variável dependente antes da modelagem melhora o erro relativo médio (mas aumenta o RMSE) em comparação com a modelagem da variável dependente sem transformação. Você irá comparar os resultados de model.log do exercício anterior com o modelo model.abs.

```{r, message=FALSE, warning=FALSE}

# fórmula do modelo fmla.abs
fmla.abs <- Income2005 ~ Arith + Word + Parag + Math + AFQT

# modelo sem transformação da variável dependente
model.abs <- lm(fmla.abs, income_train)
summary(model.abs)

# adicionando as predições no dataset de teste
income_test <- income_test %>%
  mutate(pred.absmodel = predict(model.abs, income_test), # predições do modelo model.abs
         pred.logmodel = exp(predict(model.log, income_test))) # predições do modelo model.log

# juntando as predições e calculando os residuais e o erro relativo
income_long <- income_test %>% 
  gather(key = modeltype, value = pred, pred.absmodel, pred.logmodel) %>%
  mutate(residual = pred - Income2005, # residuais
         relerr   = residual / Income2005) # erro relativo

# calculando o RMSE e o erro relativo e comparando
income_long %>% 
  group_by(modeltype) %>% # agrupando pela feature modeltype
  summarize(rmse = sqrt(mean(residual^2)), # RMSE
            rmse.rel = sqrt(mean(relerr^2))) # raíz da média dos erros relativos ao quadrado

```

Você viu como modelar o log de renda (variável dependente) pode reduzir o erro relativo do modelo, ao custo do aumento do RMSE, aqui temos um tradeoff e a escolha de fazer a transformação da variável dependente depende dos objetivos do seu projeto.

## 6) Transformação da variável independente

Vamos construir um modelo para predizer o preço em função do m². O dataset houseprice tem as seguintes colunas:

* price : preço da casa em unidades de $1000

* size: área

O scatterplot dos dados mostram que os dados possuem uma relação não-linear: essa forma curva mostra que o preço é baixo para casas menores, mas sobe acentuadamente à medida que a casa aumenta. Os quadráticos e tríticos costumam ser boas formas funcionais para expressar esse tipo de relação entre as variáveis. Observe que pode não haver uma razão "física" para o preço estar relacionado ao m², o quadrática da variável indenpendente é simplesmente uma aproximação da relação observada.

```{r, message=FALSE, warning=FALSE}

# carregando o dataset
houseprice <- read_excel(path = "houseprice.xlsx", sheet = 1)

ggplot(houseprice, aes(x = size, y = price)) +
  geom_point()

```

Na sequência vamos criar o modelo para predizer o preço em função do m², e vamos verificar o ajuste do modelo.

```{r, message=FALSE, warning=FALSE}

# verificando o dataset
summary(houseprice)

# criando a fórmula de preço em função de m²
fmla_sqr <- price ~ I(size^2)

# modelo com a variável independente transformada
model_sqr <- lm(fmla_sqr, houseprice)

# modelo sem transfomação da variável independente
model_lin <- lm(price ~ size, houseprice)

# fazendo predições e comparando
houseprice %>% 
  mutate(pred_lin = predict(model_lin), # predições do modelo linear
         pred_sqr = predict(model_sqr)) %>% # predições do modelo quadrático 
  gather(key = modeltype, value = pred, pred_lin, pred_sqr) %>% # juntando as predições
  ggplot(aes(x = size)) + 
    geom_point(aes(y = price)) +                  # actual prices
    geom_line(aes(y = pred, color = modeltype)) + # the predictions
    scale_color_brewer(palette = "Dark2")

```

A seguir iremos fazer a validação cruzada do modelo linear com o modelo quadrático e verificar sua acurácia.

```{r, message=FALSE, warning=FALSE}

# fórmula quadrática
fmla_sqr

# validação cruzado com 3 reamostragens
set.seed(34245) # possibilita a replicação
splitPlan <- kWayCrossValidation(nrow(houseprice), 3, NULL, NULL)

# gerando modelos lineares das reamostragens
houseprice$pred_lin <- 0 # vetor de predição

for(i in 1:3) {
  split <- splitPlan[[i]]
  model_lin <- lm(price ~ size, data = houseprice[split$train, ])
  houseprice$pred_lin[split$app] <- predict(model_lin, newdata = houseprice[split$app, ])
}

# gerando modelos quadráticos das reamostragens
houseprice$pred_sqr <- 0 # vetor de predição

for(i in 1:3) {
  split <- splitPlan[[i]]
  model_sqr <- lm(fmla_sqr, data = houseprice[split$train, ])
  houseprice$pred_sqr[split$app] <- predict(model_sqr, newdata = houseprice[split$app, ])
}

# juntando as predições para calcular os residuais
houseprice_long <- houseprice %>%
  gather(key = modeltype, value = pred, pred_lin, pred_sqr) %>%
  mutate(residuals = pred - price)

# comparando o RMSE
houseprice_long %>% 
  group_by(modeltype) %>%
  summarize(rmse = sqrt(mean(residuals^2)))

```

O modelo quadrático tem a acurácia melhor que o modelo linear.

## 7) Modelos não lineares

Agora que dominamos os modelos lineares, começaremos a examinar técnicas para modelar situações que não atendam aos pressupostos da linearidade. Isso inclui:

* prever probabilidades e frequências (valores limitados entre 0 e 1); 
* previsão de contagens (valores inteiros não-negativos e taxas associadas); 
* respostas que têm uma relação não linear, mas aditiva, com as entradas. 

Esses tipos de algoritmos citados acima são variações do modelo linear padrão.

### Modelo de regressão logística para prever probabilidades

Aqui vamos estimar a probabilidade de um pardal sobreviver a um inverno rigoroso baseado em suas características físicas. Usaremos o dataset sparrow. A variável dependente é status, e as variáveis independentes são:

* total_length: comprimento da ave da ponta do bico à ponta da cauda (mm);
* weight: peso em gramas;
* humerus: que é o comprimento do úmero, o "osso do braço" que liga a asa ao corpo (polegadas);

Para fazer o modelo de regressão logística usaremos a função glm(), é necessário especificar o argumento *family = binomial*:

Para medir a acurácia usaremos algo análogo ao R², que é o pseudo-R², que é dado por:

$$pseudoR² = 1- \frac{deviance}{null.deviance} $$
Podemos ver o deviance como algo análogo a variância: o deviance (erro) é a medida de variação em uma variável categórica. O pseudo-R² é análogo ao R² da regressão linear padrão: R² é uma medida da variância explicada pelo modelo de regressão linear. O pseudo-R² é a medida do erro explicado pelo modelo.

```{r, message=FALSE, warning=FALSE}

library(broom) # para a função glance()

# carregando o dataset
sparrow <- read.csv(file = "sparrow.txt" , sep = "")

# verificando os quantos do dataset
summary(sparrow)

# criando a coluna survived
sparrow$survived <- sparrow$status == "Survived"

# fórmula
fmla <- survived ~ total_length + weight + humerus

# modelo de regressão logísitca
sparrow_model <- glm(fmla, data = sparrow, family = binomial)

# verificando o modelo com a função summary()
summary(sparrow_model)

# verificando o modelo com a função glance()
perf <- glance(sparrow_model)

# calculando o pseudo-R²
pseudoR2 <- 1 - perf$deviance/perf$null.deviance
pseudoR2

```

Criamos um modelo de regressão logística para prever probabilidades! Ao olhar para o pseudo-R² de um modelo de regressão logística, um valor próximo a 1 é um modelo com acurácia boa.

Agora vamos prever a probabilidade de sobrevivência dos pardais usando o modelo de sobrevivência do pardal do código anterior anterior.

Ao usar a função predict() para obter as probabilidades previstas de um modelo glm(), você deve especificar o argumento *type = response*, se não a função irá devolver um resultado log-odds do evento e não a probabilidade.

```{r, message=FALSE, warning=FALSE}

# criando coluna de predição
sparrow$prob <- predict(sparrow_model, type = "response")

```

Vamos verificar a matrix de confusão desse modelo.

```{r, message=FALSE, warning=FALSE}

# definindo o treshold como a média das predições
treshold <- mean(sparrow$prob)

# criando coluna de predição
sparrow$pred <- ifelse(sparrow$prob <= treshold, 0, 1)

# matrix de confusão
table(sparrow$pred, sparrow$survived)

# acurácia
mean(sparrow$pred == 1)

```

Podemos ver que a quantidade de verdadeiros positivos (ou seja, a quantidade de vezes que o modelo predizeu que o pardal sobreviveria quando de fato ele sobreviveu) é de 42. 

A quantidade de verdadeiros negativos é de 26 (ou seja, a quantidade de vezes que o modelo predizeu que o pardal não sobreviveria quando de fato ele não sobreviveu) é de 26.

O nosso modelo aqui acertou próximo de 60% das predições que fez, essa é a nossa acurácia.

Agora vamos verificar a acurácia do modelo pela área abaixo da curva ROC.

```{r, message=FALSE, warning=FALSE}

# carregando o pacote pROC
library(pROC)

# criando a curva ROC
ROC <- roc(sparrow$survived, sparrow$pred)

# visualizando a curva ROC
plot(ROC, col = "blue")

# calculando a área abaixo da curva (AUC)
auc(ROC)

```

O ROC é uma curva de probabilidade que mostra a sensitividade (taxa de verdadeiros positivos) e a especificidade (taxa de verdadeiros negativos) de vários valores de treshold, indo de 0 a 1 provavelmente, 

A área abaixo da curva (AUC) ROC é uma medida de desempenho de modelos de classificação, quando a AUC é aproximadamente 0, o modelo está alternando entre as classes, isso significa que o modelo está prevendo classe negativa como uma classe positiva e vice-versa. A AUC representa o grau ou medida da separabilidade, ela informa quanto modelo é capaz de distinguir entre classes. Quanto maior a AUC, melhor o modelo prevê 0 como 0, e 1 como 1. Usando nosso exemplo, quanto maior a AUC, melhor o modelo distingue entre pardais que sobreviverão e pardais que não sobreviverão.

Aqui tem uma explicação mais detalhada sobre a AUC da curva ROC: <https://towardsdatascience.com/understanding-auc-roc-curve-68b2303cc9c5>

### Regressão de Poisson e quasipoisson para predizer contagens

Aqui veremos como usar técnicas de regressão para predizer contagem de dados. Predizer contagens é um problema não linear, porque as contagens são restritas a serem não lineares e inteiros.

* **Regressão linear:** prediz valores entre [−∞,∞]
* **Contagens:** inteiros no intervalo entre [0,∞]

Uma das regras da regressão de Poisson para prever contagens é que o evento que você está contando é uma distribição de Poisson: a contagem média por unidade de tempo é a mesma que a variância da contagem. Na prática, "o mesmo" significa que a média e a variância devem ser de uma ordem similar de magnitude.

Quando a variância é muito maior que a média, a regressão de Poisson não se aplica, e uma solução é usar a regressão de quasipoisson, que não assume que variância deve ser igual a média.

#### Modelo para predizer aluguél de bicicletas

Neste exercício, vamos construir um modelo para prever o número de bicicletas alugadas em uma hora em função do clima, do tipo de dia (feriado, dia útil ou fim de semana) e da hora do dia. Iremos treinar o modelo com dados do mês de julho.

O dataset contém as seguintes colunas:

* cnt: número de bicicletas alugadas por hora (variável dependente);
* hr: hora do dia (vai de 0 a 23);
* holiday: TRUE/FALSE;
* workingday: TRUE se nem é feriado e nem fim de semana, se não FALSE;
* weathersit: variável categórica com as seguintes classes "Clear to partly cloudy", "Light Precipitation", "Misty";
* temp: temperatura em °C;
* atemp: sensação térmica em °C;
* hum: huminadade
* windspeed: velocidade do vento;
* instant: index (não é uma variável)
* mnth and yr: indices de mês e ano (não é uma variável)

É necessário especificar o argumento *family = poisson* ou *family = quasipoisson* quando usar a função glm() para fitar um modelo de contagem.

```{r, message=FALSE, warning=FALSE}

# verificando a estrutura de bikesJuly
bikesJuly <- read.csv("bikesJuly.csv", sep = ",")
str(bikesJuly)

# variável dependente
outcome <- c("cnt")

# variáveis dependentes
vars <-  c("hr", "holiday", "workingday", "weathersit", "temp", "atemp", "hum", "windspeed")

# fórmula do modelo
fmla <- paste(outcome, "~", paste(vars, collapse = " + "))

# calculando a média e a variância da variável dependente
mean_bikes <- mean(bikesJuly$cnt)
mean_bikes

var_bikes <- var(bikesJuly$cnt)
var_bikes

# verificando a distribuição de frequência da variável dependente
hist(bikesJuly$cnt)

# fitando o modelo
bike_model <- glm(fmla, data = bikesJuly, family = quasipoisson)

# chamando glance()
perf <- glance(bike_model)

# calculando o pseudo-R²
pseudoR2 <- 1 - perf$deviance/perf$null.deviance
pseudoR2

```

Fizemos um modelo quasipoisson para prever contagens! Como no modelo de regressão logística, esperamos um pseudo-R² próximo de 1.

Agora vamos usar o modelo para predições para o mês de Agosto.

```{r, message=FALSE, warning=FALSE}

# estrutura do bikesAugust
bikesAugust <- read.csv("bikesAugust.csv", sep = ",")
str(bikesAugust)

# predições para o mês de agosto
bikesAugust$pred <- predict(bike_model, newdata = bikesAugust, type = "response")

# calculando o RMSE
bikesAugust %>% 
  mutate(residual = pred - cnt) %>%
  summarize(rmse  = sqrt(mean(residual^2)))

# visualizandoas predições X as observações da variável dependente
ggplot(bikesAugust, aes(x = pred, y = cnt)) +
  geom_point() + 
  geom_abline(color = "darkblue")

```

Visualizamos as previsões do modelo de bicicleta usando o gráfico de dispersão "resultado versus previsão". Como os dados de aluguel de bicicletas são dados de séries temporais, talvez você esteja interessado em saber como o modelo funciona em função do tempo. Neste exercício, você comparará as previsões e aluguéis reais em uma base horária, nos primeiros 14 dias de agosto.

```{r, message=FALSE, warning=FALSE}

# visualizando as predições e a variável cnt por data/tempo
bikesAugust %>% 
  # configurando para começar em 0, convertendo unidades para dias
  mutate(instant = (instant - min(instant))/24) %>%  
  # juntando cnt e pred
  gather(key = valuetype, value = value, cnt, pred) %>%
  filter(instant < 14) %>% # somente os primeiros 14 dias
  # visualizando...
  ggplot(aes(x = instant, y = value, color = valuetype, linetype = valuetype)) + 
  geom_point() + 
  geom_line() + 
  scale_x_continuous("Day", breaks = 0:14, labels = 0:14) + 
  scale_color_brewer(palette = "Dark2") + 
  ggtitle("Predicted August bike rentals, Quasipoisson model")

```
