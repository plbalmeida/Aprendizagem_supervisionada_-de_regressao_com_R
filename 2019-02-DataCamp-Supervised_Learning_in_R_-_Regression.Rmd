---
title: "Aprendizagem supervisioanda com R"
author: "Pedro Almeida"
date: "17 de fevereiro de 2019"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## 1) O que é uma regressão?

Na primeira parte desse código, será apresentdo o conceito de regressão do ponto de vista da aprendizagem de máquina. Será apresentado o método de regressão fundamental: a regressão linear. Mostrarei como ajustar um modelo de regressão linear e fazer previsões a partir do modelo.

### Codando uma regressão com uma variável independente

Será utilizado nesse RMarkdown os dados de desemprego de homens e mulheres dos Estados Unidos ao logo de vários anos, fonte dos dados: <http://college.cengage.com/mathematics/brase/understandable_statistics/7e/students/datasets/slr/frames/slr02.html>.

A tarefa aqui é prever a taxa de desemprego feminino a partir da taxa observada de desemprego masculino, respectivamente as variáveis no dataset são female_unemployment e male_unemployment.

```{r, message=FALSE, warning=FALSE}

# importando os dados
unemployment <- read.delim(file = "unemployment.txt", sep = "")

# verificando os quantis dos dados
summary(unemployment[,2:3])

# definindo a fórmula que expressa female_unemployment em função de male_unemployment
fmla <- female_unemployment ~ male_unemployment

# fitando o modelo em unemployment_model
unemployment_model <-  lm(fmla, data = unemployment)

# visualizando o modelo 
unemployment_model

```

O coeficiente do desemprego masculino é positivo, de modo que o desemprego feminino aumenta à medida que o desemprego masculino aumenta, lembrando que a regressão linear é a mais básica das abordagens de regressão.

### Examinando o modelo de regressão linear

Utilizando a função summary() é possível verificar os residuais do modelo, o coeficiente beta, o erro padrão, o valor t e a significancia estatística da variável independente no modelo. Assim como outras métricas de acurácia do modelo que abordarei mais a frente.

```{r, message=FALSE, warning=FALSE}

summary(unemployment_model)

```

### Fazendo predições a partir do modelo

```{r, message=FALSE, warning=FALSE}

# predizendo o desemprego entre mulheres a partir da taxa de desemprego entre homens
newrates <- data.frame(male_unemployment = 5) # taxa de desemprego entre homens igual a 5%
pred <- predict(unemployment_model, newdata = newrates)
pred

```

### Visualizando o modelo de regressão linear

```{r, message=FALSE, warning=FALSE}

library(ggplot2)

ggplot(unemployment, aes(x = male_unemployment, y = female_unemployment)) + 
  geom_point() +
  geom_smooth(method = "lm")

```

### Regressão multivariada

Nos exemplos de regressão multivariada será utilizado o dataset bloodpressure, no qual irei modelar a pressão em função o peso e idade, fonte dos dados <http://college.cengage.com/mathematics/brase/understandable_statistics/7e/students/datasets/mlr/frames/frame.html>.

```{r, message=FALSE, warning=FALSE}

# importando os dados
bloodpressure <- read.delim(file = "bloodpressure.txt", sep = "")

# verificando os quantis dos dados
summary(bloodpressure[,2:4])

# criando a fórmula
fmla <- blood_pressure ~ age + weight

# fitando o modelo: bloodpressure_model
bloodpressure_model <- lm(fmla, data = bloodpressure)

# examinando o modelo
summary(bloodpressure_model)

```

Uma das vantagens da regressão linear é que você pode interpretar os efeitos de cada variável independente. Nesse caso, os coeficientes para idade e peso são positivos, o que indica que a pressão sanguínea tende a aumentar à medida que a idade e o peso aumentam.

### Fazendo predições do modelo de regressão multivariada e visualizando

```{r, message=FALSE, warning=FALSE}

# predizendo pressão usando o modelo bloodpressure_model
bloodpressure$prediction <- predict(bloodpressure_model)

# visualizando os resultados
ggplot(bloodpressure, aes(x = prediction, y = blood_pressure)) + 
    geom_point() +
  geom_smooth(method = "lm")

```

Os resultados do modelo ficaram bem ajustados aos dados observados da variável dependente, indicando que o modelo se ajusta bem aos dados de treinamento. A partir de uma perspectiva de predição, a regressão linear multivariada se comporta da mesma forma que a simples (de uma variável).

## 2) Treinando e avaliando modelos de regressão

Agora que tivemos uma intuição sobre modelos mais básicos de regressão linear, aprenderemos a avaliar o desempenho de nossos modelos. Analisaremos a avaliação de um modelo graficamente e analisaremos duas métricas básicas para modelos de regressão. Também aprenderemos como treinar um modelo de modo  que ele funcione bem para dados não vistos no dataset, e não apenas em dados de treinamento.

### Avaliando o modelo unemployment_model graficamente

Aqui visualizaremos o quanto o modelo e suas predições podem errar. Na sequência faremos o cálculo do quanto um modelo pode errar em média.

```{r, message=FALSE, warning=FALSE}

# predição do modelo
unemployment$predictions <- predict(unemployment_model)

# predição X variável dependente
ggplot(unemployment, aes(x = predictions, y = female_unemployment)) + 
  geom_point() +
  geom_smooth(method = "lm")

# calculando o residual
unemployment$residuals <- unemployment$female_unemployment - unemployment$predictions

# visualizando os residuais do modelo
ggplot(unemployment, aes(x = predictions, y = residuals)) + 
  geom_pointrange(aes(ymin = 0, ymax = residuals)) + 
  geom_hline(yintercept = 0, linetype = 3) + 
  ggtitle("residuals vs. linear model prediction")

```

### Raíz da média dos residuais ao quadrado

Em inglês é root-mean-square error (RMSE), que mostra o quanto a predição do modelo está errando, essa é uma das métricas de acurácia de um modelo de regressão linear.

```{r, message=FALSE, warning=FALSE}

# criando um objeto para os residuais do modelo
res <- unemployment$residuals

# calculando a RMSE
rmse <- sqrt(mean(res^2))
rmse

# calculando o desvio padrão da variável dependente
sd_unemployment <- sd(unemployment$female_unemployment)
sd_unemployment

```

Um RMSE menor que o desvio padrão da variável dependente, sugere um modelo que prevê bem.

### Cálculo do R²

Agora que vimos o RMSE das previsões do modelo, você examinará como o modelo se ajusta aos dados: ou seja, quanto de variação ele explica, e isso é feito usando R².

o R² é dado por:

$$R² = 1- \frac{\sum_{i=1}^n (y_i-\hat{y}_i)^2}{\sum_{i=1}^n (y_i-\overline{y})^2} $$

O R² sempre vai de 0 até 1, indicando em percentagem o quanto o modelo consegue explicar os valores observados da variável dependente.

Uma maneira que gosto de pensar o R² é da seguinte maneira:

1) Olhando a divisão sem o 1 subtraindo fica mais intuitivo entender o R²; 

2) O numerador é a **soma dos quadrados dos residuais** do modelo, lembra que vimos os residuais do modelo um pouco mais acima no código? Então, aqui somamos todas as diferenças entre os valores observados da variável dependente e as predições do modelo (que são os y com chapéu) e elevamos ao quadrado para eliminar os possíveis sinais negativos dessas subtrações;

3) O denominador é a **soma dos quadrados dos erros** dos valores observados da variável dependente. Essse "erro" é a diferença entre os valores observados da variável dependente e a média da variável dependente (o y com traço em cima), elevamos ao quadrado para evitar diferenças com sinal negativo e somamos todos os quadrados dos erros;

4) Legal, a divisão entre a **soma dos quadrados dos residuais** do modelo e a **soma dos quadrados dos erros** da variável dependente, nos mostra o quanto da variável dependente é explicada pelo modelo como se fosse explicada pela média da variável dependente (e claro, nós queremos que nosso modelo explique melhor do que a média da variável dependente ok?). Exemplo: se essa divisão for igual a 0,2 quer dizer que 20% da variável dependente é explicada pelo modelo assim como é explicada pela média da variável dependente, ou seja, 20% das vezes não há diferença entre os residuais do modelo (que é o quanto o modelo erra) e o erro da variável dependente;

5) Logo, a soma dos residuais do modelo é bem menor que a soma dos erros da variável dependente, isso quer dizer que 80% das vezes o modelo está mais ajustado a distribuição dos dados da variável dependente e explica a variável dependente melhor que a média, ou seja 80% da variável dependente é explicada pelo modelo!

Agora vamos ver na prática:

```{r, message=FALSE, warning=FALSE}

# cálculo do da soma dos residuais ao quadrado (numerador)
rss <- sum(unemployment$residuals^2)
rss

# cálculo da soma dos erros ao quadrado (denominador)
fe_mean <- mean(unemployment$female_unemployment) # média da variável dependente
tss <- sum((unemployment$female_unemployment - fe_mean)^2)
tss

# cálculo do R²
rsq <- 1 - (rss/tss)
rsq

```

Legal! o R² é de 0,8213157, isto significa que 82,13% da variável dependente consegue ser explicada pelo modelo!

### Gerando datasets de treino e teste

Para os seguintes exemplos usarei o dataset mpg do pacote ggplot2, esse dataset contém características de vários modelos de carros com diferentes anos de fabricação. O objetivo aqui será predizer o consumo de combustível na cidade e na estrada pelos carros.

Nós iremos explodir o dataset mpg em um dataset de treino contendo 75% das observações do dataset, e um de treino contendo 25% das observações. 

```{r, message=FALSE, warning=FALSE}

# explorando o dataset
summary(mpg)
dim(mpg)

# criando a amostra aleatória do data set
set.seed(1)
sample_rows <- sample(nrow(mpg), nrow(mpg) * 0.75)

# criando o data set de treino
mpg_train <- mpg[sample_rows, ]

# criando o data set de teste
mpg_test <- mpg[-sample_rows, ]

# Use nrow() to examine mpg_train and mpg_test
nrow(mpg_train)
nrow(mpg_test)

```

### Treinando o modelo usando os datasets de treino e de teste

```{r, message=FALSE, warning=FALSE}

# criando a fórmula expressando o consumo de combustível urbano (feature cty) em função do consumo na estrada (feature hwy)
(fmla <- cty ~ hwy)

# modelo utilizando o dataset de treino 
mpg_model <- lm(fmla, data = mpg_train)

# verificando o modelo
summary(mpg_model)

```

A seguir utilizaremos o modelo mpg_model para predições sobre o dataset de treino 

```{r, message=FALSE, warning=FALSE}

library(Metrics) # para função rmse
library(tsensembler) # para função r_squared

# predizendo o consumo urbano de combustível pelo consumo na estrada usando o dataset de treino
mpg_train$pred <- predict(mpg_model)

# predizendo o consumo urbano de combustível pelo consumo na estrada usando o dataset de teste
mpg_test$pred <- predict(mpg_model, newdata = mpg_test)

# verificando o erro (RMSE) dos datasets de treino e de teste
rmse_train <- rmse(mpg_train$pred, mpg_train$cty)
rmse_train

rmse_test <- rmse(mpg_test$pred, mpg_test$cty)
rmse_test

# verificando o R² dos datasets de treino e de teste
rsq_train <- r_squared(mpg_train$pred, mpg_train$cty)
rsq_train

rsq_test <- r_squared(mpg_test$pred, mpg_test$cty)
rsq_test

# visualizando as predições (no eixo x) pela variável dependente cty (no eixo y) do dataset de teste
ggplot(mpg_test, aes(x = pred, y = cty)) + 
  geom_point() + 
  geom_smooth(method = "lm")

```

Impressionante! O R² do dataset de teste está melhor que o dataset de treino.

### Validação cruzada

A validação cruzada é uma técnica para avaliar a capacidade de generalização de um modelo, a partir de um conjunto de dados. Esta técnica é amplamente empregada em problemas onde o objetivo da modelagem é a predição. Busca-se então estimar o quão preciso é este modelo na prática, ou seja, o seu desempenho para um novo conjunto de dados. Fonte: <https://pt.wikipedia.org/wiki/Validação_cruzada>

```{r, message=FALSE, warning=FALSE}

library(vtreat) # para a função kWayCrossValidation

# número de linhas do dataset
nRows <- nrow(mpg)

# criando uma lista com três reamostragens dos datasets de treino e de teste
splitPlan <- kWayCrossValidation(nRows, 3, NULL, NULL)

# verificando as reamostragens
str(splitPlan)

```

Agora vamos usar a lista de reamostragens criadas.

```{r, message=FALSE, warning=FALSE}

# rodando o 3-fold cross validation do slitPlan

k <- 3 # número de reamostragens

mpg$pred.cv <- 0 

for(i in 1:k) {
  split <- splitPlan[[i]]
  model <- lm(cty ~ hwy, data = mpg[split$train, ])
  mpg$pred.cv[split$app] <- predict(model, newdata = mpg[split$app, ])
}

```

Vamos comparar a acurácia do modelo para todos os dados e acurácia para os dados reamostrados pela validação cruzada.

```{r, message=FALSE, warning=FALSE}

# modelo de todos os dados do dataset eo RMSE
mpg$pred <- predict(lm(cty ~ hwy, data = mpg))
rmse(mpg$pred, mpg$cty)

# RMSE das predições da validação cruzada
rmse(mpg$pred.cv, mpg$cty)

```

Legal! Calculamos o erro para dados não vistos através da validação cruzada!

## 3) Outras considerações

Antes de seguir com técnicas de regressão mais avançadas, examinaremos outros problemas de modelagem: modelagem com variáveis categóricas, interações entre variáveis e quando você pode considerar a transformação de variáveis independentes (de entrada) e dependentes (de saída) antes da modelagem. Embora as técnicas de regressão mais sofisticadas gerenciem alguns desses problemas automaticamente, é importante estar ciente deles, a fim de entender quais métodos lidam melhor com esses problemas.

### Variáveis categóricas no modelo

Nessa parte, chamaremos a função model.matrix() para examinar como o R representa dados com entradas categóricas e numéricas para modelagem. Usaremos o dataset flowers do pacote Sleuth3 que possue as seguintes variáveis:

* Flowers: média de flores da planta limnanthes floccosa;

* Intensity: a intensidade de de luz que a planta recebeu;

* Time: com as classes Late e Early, que mostra quando que no ciclo de vida da planta ela recebeu mais luz com intensidade;

O objetivo aqui é prever a florada (Flowers) da planta em função do tempo (Time) e da intensidade de luz (Intensity).

```{r, message=FALSE, warning=FALSE}

library(Sleuth3)

# explorando o dataset
flowers <- case0901
flowers$Time <- ifelse(flowers$Time == 1, "Late", "Early")
str(flowers)

# usando a função unique() é possível ver quais são os valores possíveis da variável Time
unique(flowers$Time)

# fórmula que expressa Flowers em função de Intensity e Time
fmla <- as.formula("Flowers ~ Intensity + Time")

# use o fmla e a função model.matrix para ver como os dados são representados para modelagem
mmat <- model.matrix(fmla, flowers)

# verificando as primeiras 20 linhas do dataset flowers
head(flowers, n = 20)

# verificando as primeiras 20 linhas do dataset mmat
head(mmat, n = 20)

```

Agora você pode ver como a maioria das funções de modelagem no R representam variáveis categóricas internamente.

### Modelagem com variáveis categóricas

```{r, message=FALSE, warning=FALSE}

# modelo
flower_model <-  lm(fmla, data = flowers)

# usando a função summary no mmat para lembrar como fica a estruta dos dados 
summary(mmat)

# examinando o modelo
summary(flower_model)

# predizendo o número de flores
flowers$predictions <- predict(flower_model)

# visualizando as predições
ggplot(flowers, aes(x = predictions, y = Flowers)) + 
  geom_point() +
  geom_smooth(method = "lm")

```

Legal! Fizemos um modelo com variável categórica!

### Modelando interações

Nessa parte, usaremos interações entre as variáveis para modelar o efeito do gênero e da atividade gástrica no metabolismo do álcool.

O dataset alcohol possui as seguintes variáveis:

* Metabol: taxa de matabolismo de álcool;

* Gastric: a taxa de atividade desidrogenase gástrica do álcool;

* Sex: sexo masculino ou feminino;

```{r, message=FALSE, warning=FALSE}

library(robustbase) # para importar o dataset alcohol

alcohol <- read.csv("alcohol.csv", sep = ";")

# alcohol is in the workspace
summary(alcohol)

# fórmula do modelo sem interação
fmla_add <- Metabol ~ Gastric + Sex

# fórmula com interação entre variáveis
fmla_interaction <- Metabol ~  Gastric + Gastric:Sex

# fitando o modelo sem interação
model_add <- lm(fmla_add, data = alcohol)

# fitando o modelo com interação
model_interaction <- lm(fmla_interaction, data = alcohol)

# verificando os dois modelos
summary(model_add)
summary(model_interaction)

```

A interação entre as variáveis parece dar um melhor ajuste aos dados.

Como esse dataset é pequeno, usaremos a validação cruzada para simular predições com dados não vistos.

```{r, message=FALSE, warning=FALSE}

library(tidyverse) # para as funções gather, mutate etc

# criando o arquivo com 3 reamostragens
set.seed(34245)  # set the seed for reproducibility
splitPlan <- kWayCrossValidation(nrow(alcohol), 3, NULL, NULL)

# modelo das reamostragens sem interação
alcohol$pred_add <- 0  # vetor de predição

for(i in 1:3) {
  split <- splitPlan[[i]]
  model_add <- lm(fmla_add, data = alcohol[split$train, ])
  alcohol$pred_add[split$app] <- predict(model_add, newdata = alcohol[split$app, ])
}

# modelo das reamostragens com interação
alcohol$pred_interaction <- 0 # vetor de predição

for(i in 1:3) {
  split <- splitPlan[[i]]
  model_interaction <- lm(fmla_interaction, data = alcohol[split$train, ])
  alcohol$pred_interaction[split$app] <- predict(model_interaction, newdata = alcohol[split$app, ])
}

# RMSE
alcohol %>% 
  gather(key = modeltype, value = pred, pred_add, pred_interaction) %>%
  mutate(residuals = Metabol - pred) %>%
  group_by(modeltype) %>%
  summarize(rmse = sqrt(mean(residuals^2)))

```

A validação cruzada mostrou aqui que um modelo com interação dá  melhores predições.